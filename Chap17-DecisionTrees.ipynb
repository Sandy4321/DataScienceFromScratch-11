{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a decision tree?\n",
    "\n",
    "\"A decision tree uses a tree structure to represent a number of possible decision pathsand an outcome for each path.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"They’re very easy to understand and interpret, and the process by which they reach a prediction is completely transparent.\"\n",
    "- \"decision trees can easily handle a mix of numeric and categorical attributes and can even classify data for which attributes are missing.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"At the same time, finding an “optimal” decision tree for a set of training data is computationally a very hard problem.\"\n",
    "- \"More important, it is very easy (and very bad) to build decision trees that are overfitted to the training data, and that don’t generalize well to unseen data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"we’d like to choose questions whose answers give a lot of information about what our tree should predict. If there’s a single yes/no question for which 'yes' answers always correspond to True outputs and “no” answers to False outputs (or vice versa), this would be an awesome question to pick. Conversely, a yes/no question\n",
    "for which neither answer gives you much new information about what the prediction should be is probably not a good choice.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"We capture this notion of 'how much information' with **entropy**. \\[...\\] We use it to represent the uncertainty associated\n",
    "with data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Imagine that we have a set $S$ of data, each member of which is labeled as belonging to one of a finite number of classes $C_1, ..., C_n$.\"\n",
    "\n",
    "- \"If all the data points belong to a single class, then there is no real uncertainty, which means we’d like there to be low entropy.\"\n",
    "- \"If the data points are evenly spread across the classes, there is a lot of uncertainty and we’d like there to be high entropy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"In math terms, if $p_i$ is the proportion of data labeled as class $c_i$ , we define the entropy as:\"\n",
    "\n",
    "$H(S) = - p_1\\ \\log_{2} p_1 - ... - p_n\\ \\log_{2} p_n$\n",
    "\n",
    "with the (standard) convention that $0\\ \\log 0 = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"each term $− p_i \\log_{2} p_i $ is non-negative and is close to zero precisely when p i is either close to zero or close to one\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7e520f5f28>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VNX9//HXZ7ITIBAIiyEhAQJh3wZQVKwriAq4Y6tia8UNbbXVurVaa6vVr/tSXFurtYg7Kq6ICihIkDVAIIQlgQCBkAUSsn5+f2TsL02DmZBk7iyf5+ORhzNzz535XBLfuTn33HNEVTHGGBMaXE4XYIwxxncs9I0xJoRY6BtjTAix0DfGmBBioW+MMSHEQt8YY0KIhb4xxoQQC31jjAkhFvrGGBNCwp0uoKGuXbtqSkqK02UYY0xAWbFixT5VTWiqnd+FfkpKChkZGU6XYYwxAUVEtnvTzrp3jDEmhFjoG2NMCLHQN8aYEGKhb4wxIcRC3xhjQoiFvjHGhBALfWOMCSF+N07fBJ/aWmX/oUryi8vZd7CC4vIqSsqrOVRZTU2NUl2rKBAV7iI6IoyYiDA6t4sgPjaSLu0j6RkXQ2yU/aga0xrs/yTTqvKLy1m1o4gN+SVs2nOQzXtLyS0sp7KmtkXvGx8bSa/OMfRLaE9a9w70796eoYlxdOsY3UqVGxMaLPRNi+wsKmfx5gK+3ryPjG2F7CmpAMAlkNIlln7d2nPawO4c0ymGHnHRdOsQRVxMBHExEcRGhRPuEsJcAkBFdS0V1bWUV9ZQeKiSA2WV7DtYwc6icvIOlJNbWMY3W/bz9sqd//n8nnHRDO/VCXdKZ47t04VBPTvi8ryfMeZ/WeibZlFVsvaUMn/tbj5am8/mvQcB6NYhimP7dGFkcidGJndmYM8ORIWHNeu9oyPCiI4IIy4mgh5xRz6DLy6vYvOeUtbkFbM6r4iVO4r4OHM3AHExEZzQrysnp3fjJwMS6No+6ugP1pggZKFvvLK39DBvf7+TNzJy2VJwCJfA2NR4Lh4zkAn9E0jr1h4R35xhx8VE4E6Jx50S/5/X8ovLWZqzn2+y9/PVpgI+XJuPCIxK7szkoT2ZPLQHPeNifFKfMf5MVNXpGv6L2+1Wm3DNP6gqy7YW8tLirSzYuJeaWmVMSmemjUxk4uAefnsWrapk7irhi417+WjdbjbklwAwNiWe80YlMnlYTzpGRzhcpTGtS0RWqKq7yXYW+qahmlrlgzW7eH5RDut2ltC5XQQXjUniIncSfRPaO11es+UUHOTDNfm8s2onOQWHiAp3MXloTy49NplRyZ199heKMW2pVUNfRCYBjwNhwAuq+kCD7dcA1wM1wEFgpqquF5EUYAOQ5Wm6VFWv+bHPstB3Tm2t8sHafB77fBM5BYfokxDLL0/ow3mjEomOaF7/vD9SVVblFvHmijzeW7WLgxXVpPfowGXH9ea8kb2IiQz8YzShq9VCX0TCgE3A6UAesBy4RFXX12vTUVVLPI+nANep6iRP6H+gqkO8LdxC3xlfbSrgLx9uIGtPKQO6d+DXp6UxcXCPoB0Jc6iimnmrd/HKt9tZn1/318xlx/bm0uN6062DDQM1gcfb0PfmQu5YIFtVczxvPAeYCvwn9H8IfI9YwL/6jMwRZe89yJ8/XM/CrAJSurTjyUtGctbQnkEb9j+IjQrnkrHJTB+TxHdbC3lh8VaeXJjN7K9zuNidxNUn9aFX53ZOl2lMq/Mm9BOB3HrP84BxDRuJyPXAzUAkcEq9TakishIoAe5S1UVHX65pLYeranjqi2xmf7WFmIgw7pw8kMvH9272MMtAJyKM69OFcX26sHXfIZ77egtzlu/g39/t4LxRidxwShpJ8Rb+Jnh4071zITBRVX/peX4ZMFZVbzhC+5962s8QkSigvaruF5HRwLvA4AZ/GSAiM4GZAMnJyaO3b/dq1S9zlJbl7Of2t9eSs+8Q541K5I7JA/12JI4TdhWV8+xXW/j38lxUleljkpl1Sj+6292/xo+1Zp/+ccA9qjrR8/x2AFW9/wjtXcABVY1rZNuXwG9V9Yid9tan33YOV9Xw4MdZvLRkK706x3D/eUM5Ma3JdZRDVn5xOU8syOaNjFzCw4SrTuzD1Sf1pb3NA2T8kLeh780sm8uBNBFJFZFIYDowr8GHpdV7ehaw2fN6gudCMCLSB0gDcrw7BNOasnaXMu3pJby0ZCuXH9ebT2+aYIHfhJ5xdb8YF/zmJE4f1IMnv8jmJw8t5NWl26lu4VxCxjilydBX1WpgFvAJdcMv56pqpojc6xmpAzBLRDJFZBV1/fozPK9PANaIyGrgTeAaVS1s9aMwP2rOdzs456nF7DtYwUtXuLl36hDaRdrZqrd6d4nlyUtG8u71x9Ona3vuencd5zy1hGU5+50uzZhms5uzgtjhqhrufi+T1zNyOTGtK49cNIKEDtZ33xKqykfrdvPnDzews6icKcOP4c6zBlp/v3Fcaw7ZNAFoZ1E517yygrU7i5l1cj9uOr3/f2azNEdPRJg8tCcnD+jG7K+28LevtrBw415umTSAn43rbf/Gxu/ZmX4QWpNXxJUvZ3C4soaHLxrOGYN7OF1S0Nq27xC/f28dizbvY3ivOB44fxgDe3Z0uiwTglrzQq4JIJ9m7uaiZ78lMszFW9eNt8BvYyldY/nnL8by+PQR7Cwq55wnF/PoZ5uorLYLvcY/WegHkX9+u42rX13BgB4deff64+nfvYPTJYUEEWHqiEQ+u+kkzhl+DI8v2Mw5Ty5mbV6x06UZ8z8s9IOAqvLkgs384b1MThvYnTlXHWsXbB3QOTaSRy8ewUtXuCkqr+TcZ5bw+OebqbLhncaPWOgHOFXlL/M38PBnmzhvZCJ/+9komy3SYaekd+fTX5/EWcN68ujnm7jgb9+QU3DQ6bKMASz0A5qqcte763h+0VZmHNeb/7twOOFh9i31B3HtInh8+kie/ukotheWcdYTi5nrmdbBGCdZQgQoVeWP76/nX8t2cPVJfbhnyuCgnxkzEJ01rCcf/2oCI5M7cetba7j+te8pLqtyuiwTwiz0A5Cq8ucPN/CPb7bxyxNSuW1Suq3+5Md6xEXz6pXjuO3MdD7N3MPkJxaxKrfI6bJMiLLQD0CPfLaJFxbXdencedZAC/wA4HIJ15zUlzevHY8IXDj7G15cvNW6e4zPWegHmH8s2cqTX2QzfUwS90wZbIEfYEYkdeLDG07k5AHd+NMH67nm1RWUHrbuHuM7FvoB5IM1u/jjB+s5fVB37ps2xAI/QMW1i+DZy0Zz11kD+XzDXqY+tYRNe0qdLsuECAv9APHNln3c/Ppq3L078+QlI22UToATEX55Yh/+fdWxlFZUM/WpJby/epfTZZkQYMkRAHIKDnLNKyvo3aUdL1w+hugIG4cfLMamxvPhDScw+JiO3PDvlfz1443U1Fo/v2k7Fvp+rrisiitfziAizMVLV4whrl2E0yWZVtatYzSvXXUsPx2XzN++3MKVLy+nuNz6+U3bsND3Y1U1tVz32gryDpQx+7LRtkB3EIsMd/GXc4dy37QhLN68j3OfWcK2fYecLssEIQt9P3bfB+tZkr2fv5w7lDEp8U6XY3zg0mN7869fjuPAoUqmPbOEb7fY6lymdVno+6l3Vubx8rfb+eUJqVzoTnK6HOND4/p04d3rj6dr+ygue3EZc5fnOl2SCSJehb6ITBKRLBHJFpHbGtl+jYisFZFVIrJYRAbV23a7Z78sEZnYmsUHq6zdpdz+9lrGpsZz25npTpdjHNC7SyxvXzee4/p24da31vB/n2TZjVymVTQZ+iISBjwNnAkMAi6pH+oer6nqUFUdATwIPOLZdxAwHRgMTAKe8byfOYLSw1Vc++oK2kdF8JQNzQxpHaMjeOmKMUwfk8RTC7P59eurqKiucbosE+C8SZSxQLaq5qhqJTAHmFq/gaqW1HsaC/xwSjIVmKOqFaq6Fcj2vJ9phKpy21tr2V5YxlM/HUk3W2w75EWEubj/vKHcMnEA763axeUvfmcje0yLeBP6iUD9TsU8z2v/RUSuF5Et1J3p39icfU2duRm5fLg2n9+c0Z9j+3RxuhzjJ0SE60/ux2MXj+D7HQe4aPa37C4+7HRZJkB5E/qN3ev/P52Lqvq0qvYFfgfc1Zx9RWSmiGSISEZBQYEXJQWfnIKD3DNvPeP7duGaCX2dLsf4oWkjE/n7FWPJO1DGec8sIXuvTd1gms+b0M8D6g8f6QX82P3ic4BpzdlXVZ9TVbequhMSErwoKbhUVtfyqzmriAx38chFI2xefHNEJ6R15fWrj6OyRrlg9res3HHA6ZJMgPEm9JcDaSKSKiKR1F2YnVe/gYik1Xt6FrDZ83geMF1EokQkFUgDvmt52cHl0c83sXZnMX89fyg94qwf3/y4IYlxvH3teDpGR/CzF5axePM+p0syAaTJ0FfVamAW8AmwAZirqpkicq+ITPE0myUimSKyCrgZmOHZNxOYC6wHPgauV1UbflDPiu0HmP3VFi52JzFpSE+nyzEBIrlLO9685jiS49vxi38s56O1+U6XZAKE+NvYX7fbrRkZGU6X4ROHq2qY/MQiKqpq+eSmCbSPCne6JBNgisuq+Pk/vmNVbhEPXjCcC0b3crok4xARWaGq7qba2SBwBz36+SZyCg5x/3lDLfDNUYlrF8GrvxzH+L5d+e0bq3nl221Ol2T8nIW+Q1blFvH81zlMH5PEhP6hd/HatJ52keG8MMPNaQO78fv3Mnn2qy1Ol2T8mIW+Ayqra7nljdV07xjNHWcNdLocEwSiI8L426WjOXtYT+7/aCNPLNjc9E4mJFmfggOeX5TD5r0HeekKNx2jbX580zoiwlw8Pn1k3dDfzzZRXavcdFqaLatp/ouFvo/t2F/GEws2c+aQHpyS3t3pckyQCXMJD10wnHCX8MSCzVTX1HLLxAEW/OY/LPR9SFW5e946wl3CH85pOGedMa0jzCU8cN4wwsNcPPPlFhS41YLfeFjo+9AnmbtZmFXAXWcNpGdcjNPlmCDmcgn3TR0CwN++3IJL4LdnWPAbC32fOVRRzT3z1pPeowNXjE9xuhwTAn4IflV4euEWXCLcfHp/C/4QZ6HvI7O/2sLuksM89VObI9/4jssl/HnaEFSVJ7/IJtzl4lenpTW9owlaFvo+kHegjOe+zmHK8GNw21q3xsdcLuEv5w6lulZ59PNNREW4uOYkm8k1VFno+8BfP84C4He29KFxiMsl/PX8YVRU1/LARxuJCnfx8+NTnS7LOMBCv42t2F7I+6t3ceMp/UjsZBdvjXPCXMIjFw2nsrqGP76/npiIMKaPTXa6LONj1rnchmprlXvfX0/3jlFcbX9OGz8QEebiyUtGcVL/BG5/Zy3vr/6xpTFMMLLQb0Pvr9nF6rxibpmYTqxNqGb8RGS4i9mXjmZM73huen0VX2zc43RJxocs9NtIVU0tj3y2ifQeHThvpC0LbPxLTGQYL1zhJr1nB6599XuW5ux3uiTjIxb6beT15bls31/GLRMH2PKHxi91jI7gn78YR1J8O656OYN1O4udLsn4gIV+GyivrOGJBZtx9+7MKendnC7HmCOKj43klSvH0jEmgiv+/h1b9x1yuiTTxiz028A/vtnG3tIKbp2Ubnc/Gr/XMy6Gf145llqFy15cxp6Sw06XZNqQV6EvIpNEJEtEskXktka23ywi60VkjYgsEJHe9bbViMgqz9e8hvsGm+LyKmZ/tYWTByQwNtVuxDKBoW9Ce/7x8zEcOFTJjJe+o7i8yumSTBtpMvRFJAx4GjgTGARcIiINp4hcCbhVdRjwJvBgvW3lqjrC8zWFIPf3JVspLq/itxMHOF2KMc0yrFcnZl82mi0FB5n5zwwOV9U4XZJpA96c6Y8FslU1R1UrgTnA1PoNVHWhqpZ5ni4FQnJ15pLDVby0eCtnDOrO4GPinC7HmGY7MS2B/7twOMu2FnLz3FXU1KrTJZlW5k3oJwK59Z7neV47kiuBj+o9jxaRDBFZKiLTjqLGgPHPb7ZRcriaG0+1Ca1M4Jo6IpG7zhrI/LW7uff9TFQt+IOJN3cMNXYlstGfAhG5FHADJ9V7OVlVd4lIH+ALEVmrqlsa7DcTmAmQnByYt4UfrKjmhcVbOTW9G0MS7SzfBLZfntiH3cWHeWHxVhI7xzBzgt1RHiy8OdPPA5LqPe8F/M+92yJyGnAnMEVVK354XVV3ef6bA3wJjGy4r6o+p6puVXUnJCQ06wD8xSvfbqeorIob7CzfBIk7Jg/krKE9+cv8jTZdQxDxJvSXA2kikioikcB04L9G4YjISOBZ6gJ/b73XO4tIlOdxV+B4YH1rFe8vyiqreX5RDif1T2BEUienyzGmVbhcwsMXDWdMSmd+M3c1y+yu3aDQZOirajUwC/gE2ADMVdVMEblXRH4YjfMQ0B54o8HQzIFAhoisBhYCD6hq0IX+v7/LpfBQJTee2s/pUoxpVdERYTx/uZuk+BhmvrKCLQUHnS7JtJD420Uat9utGRkZTpfhtaqaWn7y0Jckdoph7jXHOV2OMW1ix/4yzn1mCbFR4bxz3Xi6tI9yuiTTgIisUFV3U+3sjtwWmr82n51F5cyc0MfpUoxpM8ld2vH8DDd7Sg4z85UVNoY/gFnot4Cq8tzXOfRNiLU5dkzQG5XcmUcvHsGK7Qf47RurbShngLLQb4Fvtuwnc1cJV53Yx2bSNCFh8tCe/G5SOh+syeexzzc7XY45CrayRws8+3UOXdtHMc3myzch5JqT+pBTcJDHF2ymT0IsU0fYz38gsTP9o7Qhv4SvNxXw8+NTiI4Ic7ocY3xGRPjzuUMZmxrPLW+u4fsdB5wuyTSDhf5R+seSbcREhPGzcYF5B7ExLREZ7uLZS0fTMy6amf/MYGdRudMlGS9Z6B+ForJK3l21k2kjE+nULtLpcoxxROfYSF6c4aaiqparXs6grLLa6ZKMFyz0j8Lry3OpqK5lxvjeTTc2Joj169aBJ346ko27S/jN3NXU2qycfs9Cv5lqapVXlm5nXGo86T06Ol2OMY47eUA37pg8kI/W7eaxBTaix99Z6DfTwo17yTtQzozxKU6XYozfuPKEVC4c3YsnFmzmo7X5TpdjfoSFfjO9/O02enSM5vRB3Z0uxRi/ISLcd+4QRiZ34jdvrGZDfonTJZkjsNBvhi0FB1m0eR8/G5dMRJj90xlTX1R4GLMvHU37qHBmvpLBgUOVTpdkGmHJ1Qz/WrqDiDBh+lgbpmlMY7p3jObZy0azp7iC61/7nuqaWqdLMg1Y6HuporqGt1fmccagHiR0sBkGjTmSkcmdue/cIXyzZT9//Xij0+WYBmwaBi99mrmHorIqLh6T1HRjY0LcRe4k1uYV8/yirQzt1Ykpw49xuiTjYWf6Xnp9eS6JnWI4oV9Xp0sxJiD8/uxBuHt35tY37cKuP7HQ90JuYRmLs/dxkTvJZtM0xkuR4S6euXQUcTERXP3KCorLqpwuyWCh75U3MnIRgQvdvZwuxZiA0q1DNM/8bDT5xeX8+vWVdseuH/Aq9EVkkohkiUi2iNzWyPabRWS9iKwRkQUi0rvethkistnzNaM1i/eFmlplbkYeJ/VP4JhOMU6XY0zAGd27M384exALswp48otsp8sJeU2GvoiEAU8DZwKDgEtEZFCDZisBt6oOA94EHvTsGw/cDYwDxgJ3i0jn1iu/7X29qYDdJYeZbhdwjTlqlx7bm/NGJvLYgk0szNrrdDkhzZsz/bFAtqrmqGolMAeYWr+Bqi5U1TLP06XAD/0gE4HPVLVQVQ8AnwGTWqd033hzRR5dYiM5Jd3uwDXmaP0wB396j478es4qcgvLmt7JtAlvQj8RyK33PM/z2pFcCXzUnH1FZKaIZIhIRkFBgRcl+UbJ4So+27CHc4YfQ2S4Xf4wpiViIsOYfekoalW57l/f2+LqDvEmyRobrtLo1RgRuRRwAw81Z19VfU5V3arqTkhI8KIk3/h47W4qq2s515ZDNKZV9O4Sy8MXDmftzmL+9MF6p8sJSd6Efh5Qv0O7F7CrYSMROQ24E5iiqhXN2ddfvb0yjz5dYxnWK87pUowJGmcM7sHVE/rwr2U7eGdlntPlhBxvQn85kCYiqSISCUwH5tVvICIjgWepC/z6V2k+Ac4Qkc6eC7hneF7zezuLylmaU8i0kYmI2Nh8Y1rTLRMHMDY1njveXsemPaVOlxNSmgx9Va0GZlEX1huAuaqaKSL3isgUT7OHgPbAGyKySkTmefYtBP5E3S+O5cC9ntf83rxVdX+QTBthXTvGtLbwMBdPXTKS2KhwrvvX9xyqsKUWfUVU/etmCbfbrRkZGY7WoKpMfOxrOkRH8Na14x2txZhgtiR7H5e+uIxzRyTy8EXD7a/qFhCRFarqbqqdDUlpxIb8UjbtOcg0u4BrTJs6vl9Xfn1qf95euZPXl+c2vYNpMQv9Rry7aifhLuHsoT2dLsWYoDfrlH6c0K8rd8/LtInZfMBCvwFV5cM1+ZyY1pXOsZFOl2NM0AtzCY9NH0FcTASzXrP+/bZmod/AmrxidhaVM9nO8o3xma7to3hs+ghy9h3iD+9lOl1OULPQb2D+2nzCXcIZg3o4XYoxIWV8367ceEoab32fx5srbPx+W7HQr0dVmb8un+P7dSWuXYTT5RgTcm48NY1j+8Tz+3fXkb3Xxu+3BQv9etbtLCG3sJyzrGvHGEeEuYTHp48kJjKMWa+ttPl52oCFfj3z1+UT5hJOH2QzahrjlO4do3n4wuFs3F3K/fM3OF1O0LHQ91BV5q/NZ3zfLjZqxxiHnZzejStPSOXlb7fzaeZup8sJKhb6HuvzS9i+v8y6dozxE7dOGsCQxI7c+tYadhWVO11O0LDQ95i/tq5r54zBNmrHGH8QFR7Gk5eMorK6lpteX0WNra/bKiz0PT7J3MO41HjirWvHGL+R2jWWe6cOYdnWQmZ/tcXpcoKChT6wff8hsvce5LSBdgHXGH9z/qhEzhl+DI98tomVOw44XU7As9AHPt9QtwSAhb4x/kdEuG/aEHp0jOZXc1ZRerjK6ZICmoU+sGDDHtK6tSe5SzunSzHGNCIuJoLHp48g70AZd9s0DS0S8qFfcriK77YWcqqd5Rvj19wp8cw6JY23V+7k/dUBs+qq3wn50P96UwHVtcppA7s5XYoxpgk3ntKPEUmduPOdtTaM8yiFfOgv2LCX+NhIRiZ3droUY0wTwsNcPD59BDW1ys1zbRjn0fAq9EVkkohkiUi2iNzWyPYJIvK9iFSLyAUNttV41s39z9q5/qK6ppaFWXv5yYAEwly2TJsxgaB3l1junjKYpTmFPL8ox+lyAk6ToS8iYcDTwJnAIOASERnUoNkO4ArgtUbeolxVR3i+pjSy3THf7yiiqKzKRu0YE2AuHN2LM4f04OFPs1i/y1bbag5vzvTHAtmqmqOqlcAcYGr9Bqq6TVXXALVtUGObWbBhDxFhwolpXZ0uxRjTDCLCn88dSqd2kfz6dZuNszm8Cf1EoP6KxXme17wVLSIZIrJURKY11kBEZnraZBQUFDTjrVvmi417GZfahQ7RNne+MYEmPjaShy4YxqY9B3nokyynywkY3oR+Y53dzbl6kqyqbuCnwGMi0vd/3kz1OVV1q6o7ISGhGW999PKLy9m89yAT+ttZvjGB6icDunH5cb15cfFWlmTvc7qcgOBN6OcBSfWe9wK8HiSrqrs8/80BvgRGNqO+NrN4c90PyIlpvvklY4xpG7efOZA+CbH89o3VFJfb3bpN8Sb0lwNpIpIqIpHAdMCrUTgi0llEojyPuwLHA+uPttjWtGjzPrq2jyK9RwenSzHGtEBMZBiPXjSCvaUV/PF9u1u3KU2GvqpWA7OAT4ANwFxVzRSRe0VkCoCIjBGRPOBC4FkR+eFffiCQISKrgYXAA6rqeOjX1iqLs/cxIa0rIjZU05hANzypE7NO7sfb3+/k43X5Tpfj18K9aaSq84H5DV77Q73Hy6nr9mm43zfA0BbW2OrW55dQeKiSE2zUjjFBY9Yp/fhi415uf3sto3p3pluHaKdL8ksheUfuIk9//gn9LPSNCRYRYS4evXg4hypruOPttaja3bqNCdHQLyC9Rwe6dbQzAWOCSb9uHbh14gA+37CXt77f6XQ5finkQr+8soaMbQfshixjgtQvjk9lbGo8f5yXaZOyNSLkQn/Z1v1U1tTaUE1jgpTLJfzfBcOpUeV3b62xbp4GQi70F23eR2S4i7Gp8U6XYoxpI8ld2nHH5IEs2ryPV5ftcLocvxJyob948z7GpsQTHRHmdCnGmDb0s3HJnJjWlfvnbyC3sMzpcvxGSIV+4aFKsvaUclzfLk6XYoxpYyLCA+cPwyXCLW+uptbm3gdCLPSXbysEYJx17RgTEhI7xXDXWQNZmlPIq8u2O12OXwip0P9uayFR4S6G9opzuhRjjI9cPCaJCf0TuH/+RrbvP+R0OY4LudAfmdyJqHDrzzcmVIgIfz1/KOEu4ZY314R8N0/IhH7J4SoydxUzNtX6840JNT3jYvj92YP4bqt184RM6K/YfoBahWOtP9+YkHShuxcT+ifwwEcbQ3o0T8iE/ndbCwl3CSOTOztdijHGASLC/ecNxSXCbW+H7k1bIRX6w3rFERNp/fnGhKrETjHcPjmdJdn7+fd3uU3vEIRCIvTLK2tYk1dk/fnGGH46Npnxfbvwl/kbQnJunpAI/ZW5B6iqURufb4zxjOYZRk2tcuc7oTcFc0iE/rKcQlwCo1OsP98YA0nx7bhl4gAWZhXw7qrQmoI5JEL/u62FDDqmIx2jI5wuxRjjJ2aMT2FUcif++P56CkornC7HZ7wKfRGZJCJZIpItIrc1sn2CiHwvItUickGDbTNEZLPna0ZrFe6tqppaVuYeYEyKde0YY/6/MJfw4AXDKKuo4Z55obOgepOhLyJhwNPAmcAg4BIRGdSg2Q7gCuC1BvvGA3cD44CxwN0i4tM+lk17SjlcVWtDNY0x/6Nftw7ceGo/Plybz6eZu50uxye8OdMfC2Srao6qVgJzgKn1G6jqNlVdA9Q22Hci8Jm/0DR/AAANH0lEQVSqFqrqAeAzYFIr1O211bnFAIzo1cmXH2uMCRBXn9SX9B4d+P176yg5XOV0OW3Om9BPBOoPaM3zvOYNr/YVkZkikiEiGQUFBV6+tXdW5R6gc7sIkuJjWvV9jTHBISLMxYMXDKOgtIIHPtrodDltzpvQl0Ze83aMk1f7qupzqupWVXdCQusuY7g6t5jhSZ0QaawUY4yBYb06ceUJqby2bAdLc/Y7XU6b8ib084Ckes97Abu8fP+W7NtiByuq2bS3lBFJ1rVjjPlxN53en6T4GG5/ey2Hq2qcLqfNeBP6y4E0EUkVkUhgOjDPy/f/BDhDRDp7LuCe4XnNJ9bmFaMKwy30jTFNaBcZzv3nDmPrvkM89UW20+W0mSZDX1WrgVnUhfUGYK6qZorIvSIyBUBExohIHnAh8KyIZHr2LQT+RN0vjuXAvZ7XfGJ1XhEAw+0irjHGCyekdeW8UYnM/moLG3eXOF1OmxB/uwXZ7XZrRkZGq7zXta+uYH1+CV/dcnKrvJ8xJvgVHqrktEe+Ijm+HW9dO54wV2BcDxSRFarqbqpdUN+Ruyq3yM7yjTHNEh8byR/OHsSq3CJe+Xab0+W0uqAN/T0lh8kvPmz9+caYZps64hgm9E/goU+ygm4mzqAN/dW5df35I5JsEXRjTPOICH+eNoQaVe4Osikagjb0V+UWEe4SBh9joW+Mab6k+Hb8+rT+fLZ+Dx+vC54pGoI29FfnFZHeswPREbZSljHm6Fx5QirpPTpwz7xMSoNkioagDP3aWmVNbrFdxDXGtEhEmIsHzh/GntLDPPzpJqfLaRVBGfp5B8oprahmSKJ17RhjWmZEUicuP7Y3L3+7jVWea4WBLChD/4ebKtJ7dHC4EmNMMPjtxAEktI/iznfWUl3TcDLhwBKkoV8KQP/uFvrGmJbrEB3B3ecMJnNXCS9/u93pclokKEM/a3cpvbu0IzYq3OlSjDFBYvLQHvxkQAKPfJpFfnHgjt0PytDfsLuEAXaWb4xpRSLCn6bWjd0P5OUVgy70D1fVsG3fIdJ7dnS6FGNMkEmKb8eNp6bxSeYeFmzY43Q5RyXoQn/znoPUKgy0i7jGmDZw1Yl9SOvWnrvnZVJeGXjz7gdd6G/wjNwZYKFvjGkDEWEu7ps2hLwD5Tz5xWany2m2oAv9rN2lREe46N0l1ulSjDFBalyfLpw/qhfPL8ohe2+p0+U0S9CF/sbdJfTv3iFg5sA2xgSmOyan0y4ynDvfWYe/rUvyY4Iu9LN2l9pNWcaYNtelfRS/m5TOsq2FvLNyp9PleM2r0BeRSSKSJSLZInJbI9ujROR1z/ZlIpLieT1FRMpFZJXna3brlv/fCkor2HewkgE9bOSOMabtTR+TxIikTvxl/gaKywNjQrYmQ19EwoCngTOBQcAlIjKoQbMrgQOq2g94FPhrvW1bVHWE5+uaVqq7UVmeO3Ft5I4xxhdcLuG+aUMoPFTJI59mOV2OV7w50x8LZKtqjqpWAnOAqQ3aTAVe9jx+EzhVRHzeqb7RRu4YY3xsSGIclx3bm1eWbmfdzmKny2mSN6GfCOTWe57nea3RNqpaDRQDXTzbUkVkpYh8JSIntrDeH7VxdykJHaLo0j6qLT/GGGP+y81nDCA+Noq73l1Hba1/X9T1JvQbO2NveFRHapMPJKvqSOBm4DUR+Z8OdxGZKSIZIpJRUFDgRUmN27i7xC7iGmN8Li4mgjvPSmdVbhGvZ+Q2vYODvAn9PCCp3vNewK4jtRGRcCAOKFTVClXdD6CqK4AtQP+GH6Cqz6mqW1XdCQkJzT8KoLqmlk17DlroG2McMW1EImNT43nw440cOFTpdDlH5E3oLwfSRCRVRCKB6cC8Bm3mATM8jy8AvlBVFZEEz4VgRKQPkAbktE7p/63gYAVxMRGk28gdY4wDRIR7pw6m5HA1D/nxRd0m5x5W1WoRmQV8AoQBL6lqpojcC2So6jzgReAVEckGCqn7xQAwAbhXRKqBGuAaVS1siwPpGRfD8jtP8/v+NGNM8Erv0ZEZx6Xw92+2Mn1MEsP8cMlW8bc7ydxut2ZkZDhdhjHGHJWSw1Wc+vBXHBMXzTvXHY/LR7MDiMgKVXU31S7o7sg1xhgndYyO4I7J6azOK/bLi7oW+sYY08qmjUhkbErdRd2iMv+6qGuhb4wxrUxE+OPUwRSXV/HIZ5ucLue/WOgbY0wbGNizI5cfl8KrS7eTuct/7tS10DfGmDZy02n96dQuknvmZfrN9MsW+sYY00bi2kXwu0kDWL7tAO+u8o/ply30jTGmDV04OonhveK4f/5GDlZUO12Ohb4xxrQll0u4Z8pg9pZW8NQX2U6XY6FvjDFtbWRyZy4Y3YsXF+eQU3DQ0Vos9I0xxgd+Nymd6PAw/vTBekfrsNA3xhgfSOgQxa9OS2NhVgELNuxxrA4LfWOM8ZHLj0uhb0Isf/pgPRXVNY7UYKFvjDE+Ehnu4g/nDGbb/jL+vmSbIzVY6BtjjA+d1D+BU9O78eSCzewtPezzz7fQN8YYH7vr7EFU1tTy4Me+X2zFQt8YY3wstWssvzghlTdX5LE6t8inn22hb4wxDrjhlDQSOkRxz/u+nZfHQt8YYxzQPiqcWycOYOWOIt5btctnn+tV6IvIJBHJEpFsEbmtke1RIvK6Z/syEUmpt+12z+tZIjKx9Uo3xpjAdv6oXgzrFccDH22krNI38/I0GfoiEgY8DZwJDAIuEZFBDZpdCRxQ1X7Ao8BfPfsOom6R9MHAJOAZz/sZY0zIc7mEP5w9iN0lh5n95RbffKYXbcYC2aqao6qVwBxgaoM2U4GXPY/fBE4VEfG8PkdVK1R1K5DteT9jjDGAOyWec4Yfw7Nf55B3oKzNP8+b0E8E6q/um+d5rdE2qloNFANdvNzXGGNC2m1npiMCD3y0sc0/K9yLNtLIaw0vNR+pjTf7IiIzgZkAycnJXpRkjDHBI7FTDDeckkZFVQ2qSl1HSdvwJvTzgKR6z3sBDS81/9AmT0TCgTig0Mt9UdXngOcA3G63f6wpZowxPnT9yf188jnedO8sB9JEJFVEIqm7MDuvQZt5wAzP4wuAL7Ru4Ok8YLpndE8qkAZ81zqlG2OMaa4mz/RVtVpEZgGfAGHAS6qaKSL3AhmqOg94EXhFRLKpO8Of7tk3U0TmAuuBauB6VXVmajljjDGIv6zQ/gO3260ZGRlOl2GMMQFFRFaoqrupdnZHrjHGhBALfWOMCSEW+sYYE0Is9I0xJoRY6BtjTAjxu9E7IlIAbG/mbl2BfW1Qjj8LxWOG0DzuUDxmCM3jbskx91bVhKYa+V3oHw0RyfBmqFIwCcVjhtA87lA8ZgjN4/bFMVv3jjHGhBALfWOMCSHBEvrPOV2AA0LxmCE0jzsUjxlC87jb/JiDok/fGGOMd4LlTN8YY4wXAib0W7I4eyDz4rhvFpH1IrJGRBaISG8n6mxNTR1zvXYXiIiKSFCM8PDmuEXkIs/3O1NEXvN1ja3Ni5/vZBFZKCIrPT/jk52oszWJyEsisldE1h1hu4jIE55/kzUiMqpVC1BVv/+ibkrnLUAfIBJYDQxq0OY6YLbn8XTgdafr9tFxnwy08zy+NtCP25tj9rTrAHwNLAXcTtfto+91GrAS6Ox53s3pun1wzM8B13oeDwK2OV13Kxz3BGAUsO4I2ycDH1G38uCxwLLW/PxAOdNvyeLsgazJ41bVhar6w2rKS6lbnSyQefO9BvgT8CBw2JfFtSFvjvsq4GlVPQCgqnt9XGNr8+aYFejoeRxHIyvvBRpV/Zq6dUeOZCrwT62zFOgkIj1b6/MDJfRbsjh7IGvuwvJXUneGEMiaPGYRGQkkqeoHviysjXnzve4P9BeRJSKyVEQm+ay6tuHNMd8DXCoiecB84AbflOao5v5/3yzerJHrD1qyOHsg8/qYRORSwA2c1KYVtb0fPWYRcQGPAlf4qiAf8eZ7HU5dF89PqPuLbpGIDFHVojaura14c8yXAP9Q1YdF5DjqVugboqq1bV+eY9o0ywLlTL85i7PTYHH2QObVwvIichpwJzBFVSt8VFtbaeqYOwBDgC9FZBt1fZ7zguBirrc/4++papWqbgWyqPslEKi8OeYrgbkAqvotEE3d/DTBzKv/749WoIR+SxZnD2RNHrenq+NZ6gI/0Pt4oYljVtViVe2qqimqmkLddYwpqhroa2x68zP+LnUX7hGRrtR19+T4tMrW5c0x7wBOBRCRgdSFfoFPq/S9ecDlnlE8xwLFqprfWm8eEN072oLF2QOZl8f9ENAeeMNz3XqHqk5xrOgW8vKYg46Xx/0JcIaIrAdqgFtUdb9zVbeMl8f8G+B5EbmJui6OKwL9ZE5E/k1dF11Xz7WKu4EIAFWdTd21i8lANlAG/LxVPz/A//2MMcY0Q6B07xhjjGkFFvrGGBNCLPSNMSaEWOgbY0wIsdA3xpgQYqFvjDEhxELfGGNCiIW+McaEkP8HXshDANZKLMkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ps = np.linspace(0.01,1.0,100)\n",
    "ys = np.multiply(-ps,np.log(ps))\n",
    "\n",
    "plt.plot(ps,ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"This means the entropy will be small when every $p_i$ is close to $0$ or $1$ (i.e., when most of the data is in a single class), and it will be larger when many of the $p_i$’s are not close to $0$ (i.e., when the data is spread across multiple classes).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(class_probabilities):\n",
    "    \"\"\"\n",
    "    given a list of class probabilities, compute the entropy\n",
    "    \"\"\"\n",
    "    return sum(-p * math.log(p, 2) \n",
    "               for p in class_probabilities \n",
    "               if p) # ignore zero probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Our data will consist of pairs *(input, label)* , which means that we’ll need to compute the class probabilities ourselves. Observe that we don’t actually care which label is associated with each probability, only what the probabilities are:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def class_probabilities(labels):\n",
    "    total_count = len(labels)\n",
    "    return [count / total_count \n",
    "            for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labeled_data):\n",
    "    labels = [label for _, label in labeled_data]\n",
    "    probabilities = class_probabilities(labels)\n",
    "    return entropy(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Entropy of a Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"we’d like some notion of the entropy that results from partitioning a set of data in a certain way. We want a partition to have low entropy if it splits the data into subsets that themselves have low entropy (i.e., are highly certain), and high entropy if it contains subsets that (are large and) have high entropy (i.e., are highly\n",
    "uncertain).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Mathematically, if we partition our data $S$ into subsets $S_1 , ..., S_m$ containing proportions $q_1 , ..., q_m$ of the data, then we compute the entropy of the partition as a weighted sum:\"\n",
    "\n",
    "$H = q_1\\ H(S_1) + ... + q_m\\ H(S_m)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_entropy(subsets):\n",
    "    \"\"\"\n",
    "    find the entropy from this partition of data into subsets\n",
    "    subsets is a list of lists of labeled data\n",
    "    \"\"\"\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "    return sum( data_entropy(subset) * len(subset) / total_count \n",
    "               for subset in subsets )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"**One problem with this approach is that partitioning by an attribute with many different values will result in a very low entropy due to overfitting. \\[...\\] For this reason, you should probably try to avoid (or bucket, if appropriate) attributes with large numbers of possible values when creating decision trees.**\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Our tree will consist of decision nodes (which ask a question and direct us differently depending on the answer) and leaf nodes (which give us a prediction).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ID3 algorithm\n",
    "\n",
    "- \"If the data all have the same label, then create a leaf node that predicts that label and then stop.\"\n",
    "- \"If the list of attributes is empty (i.e., there are no more possible questions to ask), then create a leaf node that predicts the most common label and then stop.\"\n",
    "- \"Otherwise, try partitioning the data by each of the attributes\"\n",
    "- \"Choose the partition with the lowest partition entropy\"\n",
    "- \"Add a decision node based on the chosen attribute\"\n",
    "- \"Recur on each partitioned subset using the remaining attributes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"This is what’s known as a 'greedy' algorithm because, at each step, it chooses the most immediately best option. Given a data set, there may be a better tree with a worse-looking first move. If so, this algorithm won’t find it. Nonetheless, it is relatively easy to understand and implement, which makes it a good place to begin\n",
    "exploring decision trees.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Given how closely decision trees can fit themselves to their training data, it’s not surprising that they have a tendency to overfit. One way of avoiding this is a technique called random forests, in which we build multiple decision trees and let them vote on how to classify inputs\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Our tree-building process was deterministic, so how do we get random trees?\":\n",
    "\n",
    "- \"One piece involves bootstrapping data. Rather than training each tree on all the inputs in the training set, we train each tree on the result of bootstrap_sample(inputs) . Since each tree is built using different data, each tree will be different from every other tree.\"\n",
    "- \"A second source of randomness involves changing the way we chose the\n",
    "best_attribute to split on. Rather than looking at all the remaining attributes, we first choose a random subset of them and then split on whichever of those is best.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
